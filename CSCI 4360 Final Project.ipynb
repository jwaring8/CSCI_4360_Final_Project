{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Corpus Label             ID  \\\n",
      "0    GEN  sarc  GEN_sarc_0000   \n",
      "1    GEN  sarc  GEN_sarc_0001   \n",
      "2    GEN  sarc  GEN_sarc_0002   \n",
      "3    GEN  sarc  GEN_sarc_0003   \n",
      "4    GEN  sarc  GEN_sarc_0004   \n",
      "\n",
      "                                          Quote Text  \\\n",
      "0  First off, That's grade A USDA approved Libera...   \n",
      "1  watch it. Now you're using my lines. Poet has ...   \n",
      "2  Because it will encourage teens to engage in r...   \n",
      "3  Obviously you missed the point. So sorry the t...   \n",
      "4  This is pure paranoia. What evidence do you ha...   \n",
      "\n",
      "                                       Response Text  \n",
      "0  Therefore you accept that the Republican party...  \n",
      "1  More chattering from the peanut gallery? Haven...  \n",
      "2  Yep, suppressing natural behavior is always th...  \n",
      "3  I guess we all missed your point Justine, what...  \n",
      "4  Evidence, I dont need no sticking evidence. Th...  \n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/sarcasm_v2.csv')\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notsarc    2346\n",
      "sarc       2346\n",
      "Name: Label, dtype: int64\n",
      "GEN    3260\n",
      "RQ      850\n",
      "HYP     582\n",
      "Name: Corpus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset['Label'].value_counts())\n",
    "print(dataset['Corpus'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "Y = dataset['Label'].values\n",
    "quotes = dataset['Quote Text'].values\n",
    "responses = dataset['Response Text'].values \n",
    "\n",
    "print(type(Y))\n",
    "print(type(quotes))\n",
    "print(type(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['First', 'off', ',', \"That's\", 'grade', 'A', 'USDA', 'approved', 'Liberalism', 'in', 'a', 'nutshell', '.']\n",
      "['First', 'off', ',', 'That', \"'s\", 'grade', 'A', 'USDA', 'approved', 'Liberalism', 'in', 'a', 'nutshell', '.']\n"
     ]
    }
   ],
   "source": [
    "#Two examples of potential tokenizers to use\n",
    "print(TweetTokenizer().tokenize(quotes[0])) #tweet tokenizer to recogonize potential emoticons and \n",
    "print(word_tokenize(quotes[0])) #more standard tokenizer on punctuation and words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, tokenizer, stopwords=stopwords.words(\"english\"), stemmer=PorterStemmer()):\n",
    "    '''\n",
    "    This function will remove stopwords from the text and perform stemming. Return tokenized sentences. \n",
    "    \n",
    "    Params:\n",
    "    text -- string we are looking at \n",
    "    tokenizer -- string of either 'twitter' or 'word' to specify which tokenizer to use\n",
    "    stopwords -- list of stopwords to remove, default is the NLTK stopwords list\n",
    "    stemmer -- stemming function to use, default is the PorterStemmer from NLTK\n",
    "    \n",
    "    Returns:\n",
    "    cleaned_text -- text with removed stopwords and applied stemming\n",
    "    \n",
    "    '''\n",
    "    #remove stopwords \n",
    "    cleaned_text =  ' '.join([word for word in text.split() if word not in stopwords])\n",
    "        \n",
    "    #perform stemming\n",
    "    if(tokenizer == 'twitter'):\n",
    "        tokens = TweetTokenizer().tokenize(cleaned_text)\n",
    "        stemmed_tokens = [stemmer.stem(i) for i in tokens]\n",
    "    elif(tokenizer == 'word'):\n",
    "        tokens = word_tokenize(cleaned_text)\n",
    "        stemmed_tokens = [stemmer.stem(i) for i in tokens]\n",
    "    \n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(quotes.shape[0]):\n",
    "    quotes[i] = preprocess_text(quotes[i], 'twitter')\n",
    "for i in range(responses.shape[0]):\n",
    "    responses[i] = preprocess_text(responses[i], 'twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first', 'off', ',', \"that'\", 'grade', 'A', 'usda', 'approv', 'liber', 'nutshel', '.']\n",
      "['therefor', 'accept', 'republican', 'parti', 'almost', 'whole', '\"', 'grade', 'A', 'usda', 'approv', 'liber', '.', '\"', 'about', 'time', 'did', '.']\n"
     ]
    }
   ],
   "source": [
    "#let's make sure we get what we expect: tokenized sentences with no stopwords and removed stems\n",
    "print(quotes[0])\n",
    "print(responses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#See Github README for next steps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
